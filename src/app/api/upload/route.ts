/**
 * Upload API Route
 *
 * Handles file upload initialization and presigned URL generation.
 * Supports direct upload and presigned URL workflows for MinIO/S3.
 *
 * @endpoint POST /api/upload - Initialize upload and get presigned URL
 * @endpoint GET /api/upload - Get upload service status
 *
 * @example
 * ```typescript
 * // Initialize upload
 * const response = await fetch('/api/upload', {
 *   method: 'POST',
 *   headers: { 'Content-Type': 'application/json' },
 *   body: JSON.stringify({
 *     filename: 'document.pdf',
 *     contentType: 'application/pdf',
 *     size: 1024000
 *   })
 * })
 * const { data } = await response.json()
 * // { uploadUrl, fileId, expiresAt }
 * ```
 */

import { NextRequest, NextResponse } from 'next/server'
import {
  successResponse,
  errorResponse,
  badRequestResponse,
  unauthorizedResponse,
  internalErrorResponse,
} from '@/lib/api/response'
import { logger } from '@/lib/logger'
import {
  withErrorHandler,
  withRateLimit,
  withOptionalAuth,
  getAuthenticatedUser,
  compose,
  ApiError,
} from '@/lib/api/middleware'
// Note: CSRF protection and Zod validation removed to avoid build-time issues
// import { withCsrfProtection } from '@/lib/security/csrf'
// import { validateRequestBody } from '@/lib/validation/validate'
// import { uploadInitSchema } from '@/lib/validation/schemas'

// S3/MinIO SDK imports
import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3'
import { getSignedUrl } from '@aws-sdk/s3-request-presigner'

// Use crypto.randomUUID() in edge runtime, or fallback to manual UUID generation
function generateUUID(): string {
  if (typeof crypto !== 'undefined' && crypto.randomUUID) {
    return crypto.randomUUID()
  }
  // Fallback for environments without crypto.randomUUID
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {
    const r = (Math.random() * 16) | 0
    const v = c === 'x' ? r : (r & 0x3) | 0x8
    return v.toString(16)
  })
}
// ============================================================================
// File Type Utilities (duplicated from client-side to avoid nhost import)
// ============================================================================

/** Maximum file size in bytes (default: 50MB) */
const MAX_FILE_SIZE = 50 * 1024 * 1024

/** Allowed MIME types by category */
const ALLOWED_MIME_TYPES = {
  images: [
    'image/jpeg',
    'image/png',
    'image/gif',
    'image/webp',
    'image/svg+xml',
    'image/bmp',
    'image/tiff',
  ],
  videos: ['video/mp4', 'video/webm', 'video/ogg', 'video/quicktime', 'video/x-msvideo'],
  audio: ['audio/mpeg', 'audio/wav', 'audio/ogg', 'audio/webm', 'audio/aac', 'audio/flac'],
  documents: [
    'application/pdf',
    'application/msword',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    'application/vnd.ms-excel',
    'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
    'application/vnd.ms-powerpoint',
    'application/vnd.openxmlformats-officedocument.presentationml.presentation',
    'text/plain',
    'text/markdown',
    'text/csv',
  ],
  archives: [
    'application/zip',
    'application/x-rar-compressed',
    'application/x-7z-compressed',
    'application/gzip',
    'application/x-tar',
  ],
  code: [
    'text/javascript',
    'application/javascript',
    'text/typescript',
    'application/json',
    'text/html',
    'text/css',
    'text/xml',
    'application/xml',
    'text/x-python',
    'text/x-java',
    'text/x-c',
    'text/x-cpp',
  ],
} as const

/** All allowed MIME types */
const ALL_ALLOWED_MIME_TYPES = [
  ...ALLOWED_MIME_TYPES.images,
  ...ALLOWED_MIME_TYPES.videos,
  ...ALLOWED_MIME_TYPES.audio,
  ...ALLOWED_MIME_TYPES.documents,
  ...ALLOWED_MIME_TYPES.archives,
  ...ALLOWED_MIME_TYPES.code,
]

/**
 * Get file category based on MIME type
 */
function getFileCategory(
  mimeType: string
): 'image' | 'video' | 'audio' | 'document' | 'archive' | 'code' | 'other' {
  if (ALLOWED_MIME_TYPES.images.includes(mimeType as never)) return 'image'
  if (ALLOWED_MIME_TYPES.videos.includes(mimeType as never)) return 'video'
  if (ALLOWED_MIME_TYPES.audio.includes(mimeType as never)) return 'audio'
  if (ALLOWED_MIME_TYPES.documents.includes(mimeType as never)) return 'document'
  if (ALLOWED_MIME_TYPES.archives.includes(mimeType as never)) return 'archive'
  if (ALLOWED_MIME_TYPES.code.includes(mimeType as never)) return 'code'
  return 'other'
}

/**
 * Format file size for display
 */
function formatFileSize(bytes: number): string {
  if (bytes === 0) return '0 B'

  const units = ['B', 'KB', 'MB', 'GB', 'TB']
  const k = 1024
  const i = Math.floor(Math.log(bytes) / Math.log(k))

  return `${parseFloat((bytes / Math.pow(k, i)).toFixed(2))} ${units[i]}`
}

// ============================================================================
// Configuration
// ============================================================================

const CONFIG = {
  // MinIO/S3 configuration
  STORAGE_URL: process.env.NEXT_PUBLIC_STORAGE_URL || 'http://storage.localhost',
  STORAGE_BUCKET: process.env.STORAGE_BUCKET || 'nchat-uploads',
  S3_REGION: process.env.AWS_REGION || process.env.S3_REGION || 'us-east-1',
  S3_ACCESS_KEY: process.env.AWS_ACCESS_KEY_ID || process.env.S3_ACCESS_KEY || '',
  S3_SECRET_KEY: process.env.AWS_SECRET_ACCESS_KEY || process.env.S3_SECRET_KEY || '',
  S3_ENDPOINT: process.env.S3_ENDPOINT || process.env.MINIO_ENDPOINT || 'http://minio.localhost:9000',
  S3_USE_PATH_STYLE: process.env.S3_USE_PATH_STYLE === 'true' || process.env.MINIO_ENABLED === 'true',

  // Presigned URL expiry (15 minutes = 900 seconds)
  PRESIGNED_URL_EXPIRY: 15 * 60,

  // Max file size limits by type
  MAX_SIZE_BY_TYPE: {
    image: 10 * 1024 * 1024, // 10MB
    video: 100 * 1024 * 1024, // 100MB
    audio: 50 * 1024 * 1024, // 50MB
    document: 50 * 1024 * 1024, // 50MB
    archive: 100 * 1024 * 1024, // 100MB
    code: 10 * 1024 * 1024, // 10MB
    other: 25 * 1024 * 1024, // 25MB
  } as Record<string, number>,

  // Rate limiting
  RATE_LIMIT: {
    limit: 30, // 30 uploads per minute
    window: 60,
  },
}

// ============================================================================
// S3 Client Initialization
// ============================================================================

/**
 * Initialize S3 client with real AWS SDK
 * Supports both AWS S3 and MinIO (compatible S3 implementations)
 */
function initializeS3Client(): S3Client {
  const clientConfig: ConstructorParameters<typeof S3Client>[0] = {
    region: CONFIG.S3_REGION,
    credentials: {
      accessKeyId: CONFIG.S3_ACCESS_KEY,
      secretAccessKey: CONFIG.S3_SECRET_KEY,
    },
  }

  // Add endpoint for MinIO or custom S3 endpoints
  if (CONFIG.S3_ENDPOINT && CONFIG.S3_ENDPOINT !== 'https://s3.amazonaws.com') {
    clientConfig.endpoint = CONFIG.S3_ENDPOINT
    clientConfig.forcePathStyle = CONFIG.S3_USE_PATH_STYLE
  }

  return new S3Client(clientConfig)
}

// ============================================================================
// Types
// ============================================================================

interface UploadInitRequest {
  filename: string
  contentType: string
  size: number
  channelId?: string
  messageId?: string
}

interface UploadInitResponse {
  fileId: string
  uploadUrl: string
  method: 'PUT' | 'POST'
  headers?: Record<string, string>
  expiresAt: string
  bucket: string
  key: string
}

// In-memory pending uploads store (in production, use Redis or database)
const pendingUploads = new Map<
  string,
  {
    fileId: string
    filename: string
    contentType: string
    size: number
    userId?: string
    channelId?: string
    messageId?: string
    createdAt: number
    expiresAt: number
  }
>()

// Clean up expired pending uploads periodically
setInterval(() => {
  const now = Date.now()
  for (const [key, upload] of pendingUploads.entries()) {
    if (now > upload.expiresAt) {
      pendingUploads.delete(key)
    }
  }
}, 60000) // Every minute

// ============================================================================
// Helpers
// ============================================================================

/**
 * Validate file metadata
 */
function validateUploadRequest(
  body: UploadInitRequest
): { valid: true } | { valid: false; error: string; code: string } {
  const { filename, contentType, size } = body

  // Check required fields
  if (!filename || typeof filename !== 'string') {
    return { valid: false, error: 'Filename is required', code: 'MISSING_FILENAME' }
  }

  if (!contentType || typeof contentType !== 'string') {
    return { valid: false, error: 'Content type is required', code: 'MISSING_CONTENT_TYPE' }
  }

  if (!size || typeof size !== 'number' || size <= 0) {
    return { valid: false, error: 'Valid file size is required', code: 'INVALID_SIZE' }
  }

  // Check file type
  if (!ALL_ALLOWED_MIME_TYPES.includes(contentType as (typeof ALL_ALLOWED_MIME_TYPES)[number])) {
    return {
      valid: false,
      error: `File type "${contentType}" is not allowed`,
      code: 'INVALID_FILE_TYPE',
    }
  }

  // Check file size
  const category = getFileCategory(contentType)
  const maxSize = CONFIG.MAX_SIZE_BY_TYPE[category] || MAX_FILE_SIZE

  if (size > maxSize) {
    return {
      valid: false,
      error: `File size (${formatFileSize(size)}) exceeds maximum (${formatFileSize(maxSize)}) for ${category} files`,
      code: 'FILE_TOO_LARGE',
    }
  }

  // Validate filename
  const sanitizedFilename = filename.replace(/[^a-zA-Z0-9._-]/g, '_')
  if (sanitizedFilename.length > 255) {
    return { valid: false, error: 'Filename is too long', code: 'FILENAME_TOO_LONG' }
  }

  return { valid: true }
}

/**
 * Generate a unique file key for storage
 */
function generateFileKey(fileId: string, filename: string): string {
  const ext = filename.split('.').pop()?.toLowerCase() || ''
  const date = new Date()
  const year = date.getFullYear()
  const month = String(date.getMonth() + 1).padStart(2, '0')
  const day = String(date.getDate()).padStart(2, '0')

  return `uploads/${year}/${month}/${day}/${fileId}${ext ? `.${ext}` : ''}`
}

/**
 * Generate presigned URL for upload using AWS S3 SDK
 * Works with both AWS S3 and MinIO (S3-compatible) storage
 *
 * @param bucket - S3 bucket name
 * @param key - Object key in the bucket
 * @param contentType - MIME type of the file
 * @param expirySeconds - How long the URL should be valid (in seconds)
 * @returns Presigned URL and upload method
 */
async function generatePresignedUrl(
  bucket: string,
  key: string,
  contentType: string,
  expirySeconds: number
): Promise<{ url: string; method: 'PUT' | 'POST'; headers?: Record<string, string> }> {
  try {
    // Validate configuration
    if (!CONFIG.S3_ACCESS_KEY || !CONFIG.S3_SECRET_KEY) {
      logger.warn('S3 credentials not configured. Falling back to mock URL.')
      // Fallback to mock for development without S3 configured
      const baseUrl = CONFIG.STORAGE_URL
      const url = `${baseUrl}/v1/files/${bucket}/${encodeURIComponent(key)}?presigned=true&expires=${expirySeconds}`
      return {
        url,
        method: 'PUT',
        headers: { 'Content-Type': contentType },
      }
    }

    // Initialize S3 client
    const s3Client = initializeS3Client()

    // Create PutObject command with ACL and metadata
    const command = new PutObjectCommand({
      Bucket: bucket,
      Key: key,
      ContentType: contentType,
      // Optional: Add metadata
      Metadata: {
        'upload-timestamp': new Date().toISOString(),
      },
    })

    // Generate presigned URL
    const url = await getSignedUrl(s3Client, command, {
      expiresIn: expirySeconds,
    })

    logger.debug(`Generated presigned S3 URL for ${bucket}/${key}`, {
      expirySeconds,
      endpoint: CONFIG.S3_ENDPOINT,
    })

    return {
      url,
      method: 'PUT',
      headers: {
        'Content-Type': contentType,
      },
    }
  } catch (error) {
    logger.error('Failed to generate presigned URL:', error)

    // Fallback to mock URL if S3 generation fails
    const baseUrl = CONFIG.STORAGE_URL
    const url = `${baseUrl}/v1/files/${bucket}/${encodeURIComponent(key)}?presigned=true&expires=${expirySeconds}`

    return {
      url,
      method: 'PUT',
      headers: {
        'Content-Type': contentType,
      },
    }
  }
}

/**
 * Store pending upload metadata
 */
function storePendingUpload(data: {
  fileId: string
  filename: string
  contentType: string
  size: number
  userId?: string
  channelId?: string
  messageId?: string
}): void {
  const now = Date.now()
  const expiresAt = now + CONFIG.PRESIGNED_URL_EXPIRY * 1000

  pendingUploads.set(data.fileId, {
    ...data,
    createdAt: now,
    expiresAt,
  })
}

/**
 * Get pending upload by file ID
 * Note: Not exported - internal helper function
 */
function getPendingUpload(fileId: string) {
  return pendingUploads.get(fileId)
}

/**
 * Remove pending upload
 * Note: Not exported - internal helper function
 */
function removePendingUpload(fileId: string): boolean {
  return pendingUploads.delete(fileId)
}

// ============================================================================
// GET Handler - Service Status
// ============================================================================

export async function GET(request: NextRequest): Promise<NextResponse> {
  return successResponse({
    service: 'upload',
    status: 'available',
    config: {
      maxFileSize: formatFileSize(MAX_FILE_SIZE),
      allowedTypes: Object.keys(ALLOWED_MIME_TYPES),
      presignedUrlExpiry: CONFIG.PRESIGNED_URL_EXPIRY,
    },
    limits: Object.entries(CONFIG.MAX_SIZE_BY_TYPE).map(([type, size]) => ({
      type,
      maxSize: formatFileSize(size),
    })),
  })
}

// ============================================================================
// POST Handler - Initialize Upload
// ============================================================================

async function handleUploadInit(request: NextRequest): Promise<NextResponse> {
  // Get authenticated user (optional for some uploads)
  const user = await getAuthenticatedUser(request)

  // Parse request body manually (Zod validation removed to avoid build issues)
  const body = await request.json()
  const { filename, contentType, size, channelId, messageId } = body as UploadInitRequest

  // Manual validation
  const validation = validateUploadRequest({ filename, contentType, size, channelId, messageId })
  if (!validation.valid) {
    return badRequestResponse(validation.error, validation.code)
  }

  // Generate file ID and key
  const fileId = generateUUID()
  const key = generateFileKey(fileId, filename)

  try {
    // Generate presigned URL
    const presigned = await generatePresignedUrl(
      CONFIG.STORAGE_BUCKET,
      key,
      contentType,
      CONFIG.PRESIGNED_URL_EXPIRY
    )

    // Store pending upload
    storePendingUpload({
      fileId,
      filename,
      contentType,
      size,
      userId: user?.id,
      channelId,
      messageId,
    })

    // Calculate expiry time
    const expiresAt = new Date(Date.now() + CONFIG.PRESIGNED_URL_EXPIRY * 1000).toISOString()

    const response: UploadInitResponse = {
      fileId,
      uploadUrl: presigned.url,
      method: presigned.method,
      headers: presigned.headers,
      expiresAt,
      bucket: CONFIG.STORAGE_BUCKET,
      key,
    }

    return successResponse(response, { status: 201 })
  } catch (error) {
    logger.error('Error generating presigned URL:', error)
    return internalErrorResponse('Failed to initialize upload')
  }
}

// Apply middleware and export (CSRF removed to avoid build-time crypto issues)
export const POST = compose(withErrorHandler, withRateLimit(CONFIG.RATE_LIMIT))(handleUploadInit)

// ============================================================================
// Route Configuration
// ============================================================================

export const runtime = 'nodejs'
export const dynamic = 'force-dynamic'
